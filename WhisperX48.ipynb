{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cEAvBF4zgXX4"
   },
   "source": [
    "# WhisperX48\n",
    "\n",
    "<font size=\"3\">将 WhisperX 部署在 Google Colab 云端上，其目标是减少视频字幕制作过程中听译和打轴的繁重工作。详细信息和帮助文档可查阅 [README](https://github.com/ifeimi/Whisper48/blob/main/README.md) 文件和[我的主页](https://ifeimi.github.io/whisper48/)。  \n",
    "This IPython Notebook is designed as an implementation of WhisperX on Google Colab. The application serves to reduce the heavy and tedious work in transcription and timestamping in video-subtitling. Detailed information and help document can be found in [README](https://github.com/ifeimi/Whisper48/blob/main/README.md) and on [my website](https://ifeimi.github.io/whisper48/).   \n",
    "\\\n",
    "请按提示依次执行以下单元格，建议在开始前先将需要转录的音频文件上传到谷歌网盘中。  \n",
    "Please run the following cells in order according to the help text. It is suggested to upload your audio file to Google Drive first before you start.  \n",
    "\\\n",
    "联系作者/Contact me: yfwu0202@gmail.com.<font size=\"3\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nw72_bK3AS1d"
   },
   "outputs": [],
   "source": [
    "#@markdown **1.1 挂载你的谷歌网盘/Mount Google Drive (approx. 0.5 min)** \n",
    "#@markdown **</br><font size=\"2\">【重要】:** 务必在\"修改\"->\"笔记本设置\"->\"硬件加速器\"中选择GPU！\n",
    "#@markdown **</br>【IMPORTANT】:** Make sure you select GPU as hardware accelerator in \"Runtime\" -> \"Change runtime type\".</font><br/>\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import os\n",
    "import logging\n",
    "from IPython.display import clear_output \n",
    "\n",
    "clear_output()\n",
    "print('Please allow the connection to Google Drive in the pop-up window')\n",
    "print('请在弹出窗口中选择同意挂载谷歌云盘')\n",
    "drive.mount('/drive')\n",
    "print('Google Drive mounted，please proceed to next step')\n",
    "print('谷歌云盘挂载完毕，请执行下一步')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Fjm3tYISAk9P"
   },
   "outputs": [],
   "source": [
    "#@markdown **1.2 配置运行环境/Setup environment (approx. 3 min)**\n",
    "# @markdown <br/><font size=\"2\">目前在Colab上安装WhisperX时似乎会出现一些和PyTorch版本相关的[问题](https://github.com/m-bain/whisperX/issues/165)，解决方案已经包括在这里。如果本单元格正常运行结束，只要忽略过程中产生的报错信息即可。我会继续关注这个问题。\n",
    "# @markdown <br/>Right now there seems to be [some problem](https://github.com/m-bain/whisperX/issues/165) related to PyTorch versions when installing WhisperX on Colab. Solution is already included here. If this cell successfully runs to the end, just ignore the error messages. I will continue monitoring this problem. </font><br/>\n",
    "\n",
    "! pip install geemap -q\n",
    "import geemap\n",
    "! pip install git+https://github.com/m-bain/whisperx.git -q\n",
    "! pip install light-the-torch -q\n",
    "! ltt install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1  torchtext==0.14.1\n",
    "clear_output()\n",
    "print('Environment is ready，please proceed to next step')\n",
    "print('运行环境配置完毕，请执行下一步')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "30dM9s2J27A5"
   },
   "outputs": [],
   "source": [
    "#@markdown **1.3 从谷歌云盘选择文件/Select File From Google Drive (approx. 0 min)**\n",
    "# @markdown <br/><font size=\"2\">从网盘目录中选择要转换的文件(视频/音频），单击选中文件，点击'Select'按钮以确认。\n",
    "# @markdown <br/>Navigate to the file you want to transcribe, left-click to highlight the file, then click 'Select' button to confirm.\n",
    "# @markdown <br/>若到这一步才上传文件到谷歌盘，则重复执行本单元格以刷新文件列表。\n",
    "# @markdown <br/>If the file was not uploaded until this cell, execute this cell again to refresh.</font>\n",
    "\n",
    "from ipytree import Tree, Node\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "import os\n",
    "from google.colab import output \n",
    "output.enable_custom_widget_manager()\n",
    "use_drive = True\n",
    "global drive_dir\n",
    "drive_dir = ''\n",
    "\n",
    "def file_tree():\n",
    "    # create widgets as a simple file browser\n",
    "    full_widget = widgets.HBox()\n",
    "    left_widget = widgets.VBox()\n",
    "    right_widget = widgets.VBox()\n",
    "\n",
    "    path_widget = widgets.Text()\n",
    "    path_widget.layout.min_width = '300px'\n",
    "    select_widget = widgets.Button(\n",
    "      description='Select', button_style='primary', tooltip='Select current media file.'\n",
    "      )\n",
    "    drive_url = widgets.Output()\n",
    "\n",
    "    right_widget.children = [select_widget]\n",
    "    full_widget.children = [left_widget]\n",
    "\n",
    "    tree_widget = widgets.Output()\n",
    "    tree_widget.layout.max_width = '300px'\n",
    "    tree_widget.overflow = 'auto'\n",
    "\n",
    "    left_widget.children = [path_widget,tree_widget]\n",
    "\n",
    "    # init file tree\n",
    "    my_tree = Tree(multiple_selection=False)\n",
    "    my_tree_dict = {}\n",
    "    media_names = []\n",
    "\n",
    "    def select_file(b):\n",
    "        global drive_dir \n",
    "        drive_dir = path_widget.value\n",
    "        # full_widget.disabled = True\n",
    "        clear_output()\n",
    "        print('File selected，please execute next cell')\n",
    "        print('已选择文件，请执行下个单元格')\n",
    "    #     if (out_file not in my_tree_dict.keys()) and (out_dir in my_tree_dict.keys()):\n",
    "    #         node = Node(os.path.basename(out_file))\n",
    "    #         my_tree_dict[out_file] = node\n",
    "    #         parent_node = my_tree_dict[out_dir]\n",
    "    #         parent_node.add_node(node)\n",
    "\n",
    "    select_widget.on_click(select_file)\n",
    "\n",
    "    def handle_file_click(event):\n",
    "        if event['new']:\n",
    "            cur_node = event['owner']\n",
    "            for key in my_tree_dict.keys():\n",
    "                if (cur_node is my_tree_dict[key]) and (os.path.isfile(key)):\n",
    "                    try:\n",
    "                        with open(key) as f:\n",
    "                            path_widget.value = key\n",
    "                            path_widget.disabled = False\n",
    "                            select_widget.disabled = False\n",
    "                            full_widget.children = [left_widget, right_widget]\n",
    "                    except Exception as e:\n",
    "                        path_widget.value = key\n",
    "                        path_widget.disabled = True\n",
    "                        select_widget.disabled = True\n",
    "\n",
    "                        return\n",
    "\n",
    "    def handle_folder_click(event):\n",
    "        if event['new']:\n",
    "            full_widget.children = [left_widget]\n",
    "\n",
    "    # redirect cwd to default drive root path and add nodes\n",
    "    my_dir = '/drive/MyDrive'\n",
    "    my_root_name = my_dir.split('/')[-1]\n",
    "    my_root_node = Node(my_root_name)\n",
    "    my_tree_dict[my_dir] = my_root_node\n",
    "    my_tree.add_node(my_root_node)\n",
    "    my_root_node.observe(handle_folder_click, 'selected')\n",
    "\n",
    "    for root, d_names, f_names in os.walk(my_dir):\n",
    "        folders = root.split('/')\n",
    "        for folder in folders:\n",
    "            if folder.startswith('.'):\n",
    "                continue\n",
    "        for d_name in d_names:\n",
    "            if d_name.startswith('.'):\n",
    "                d_names.remove(d_name)\n",
    "        for f_name in f_names:\n",
    "            # if f_name.startswith('.'):\n",
    "            #     f_names.remove(f_name)\n",
    "            # only add media files\n",
    "            if f_name.endswith(('mp3','m4a','flac','aac','wav','mp4','mkv','ts','flv')):\n",
    "                media_names.append(f_name)\n",
    "\n",
    "        d_names.sort()\n",
    "        f_names.sort()\n",
    "        media_names.sort()\n",
    "        keys = my_tree_dict.keys()\n",
    "\n",
    "        if root not in my_tree_dict.keys():\n",
    "          # print(f'root name is {root}') # folder path\n",
    "          name = root.split('/')[-1] # folder name\n",
    "          # print(f'folder name is {name}')\n",
    "          dir_name = os.path.dirname(root) # parent path of folder\n",
    "          # print(f'dir name is {dir_name}')\n",
    "          parent_node = my_tree_dict[dir_name]\n",
    "          node = Node(name)\n",
    "          my_tree_dict[root] = node\n",
    "          parent_node.add_node(node)\n",
    "          node.observe(handle_folder_click, 'selected')\n",
    "\n",
    "        if len(media_names) > 0:\n",
    "              parent_node = my_tree_dict[root] # parent folders\n",
    "              # print(parent_node)\n",
    "              parent_node.opened = False\n",
    "              for f_name in media_names:\n",
    "                  node = Node(f_name)\n",
    "                  node.icon = 'file' \n",
    "                  full_path = os.path.join(root, f_name)\n",
    "                  # print(full_path)\n",
    "                  my_tree_dict[full_path] = node\n",
    "                  parent_node.add_node(node)\n",
    "                  node.observe(handle_file_click, 'selected')\n",
    "        media_names.clear()\n",
    "\n",
    "    with tree_widget:\n",
    "      tree_widget.clear_output()\n",
    "      display(my_tree)\n",
    "\n",
    "    return full_widget\n",
    "\n",
    "\n",
    "tree= file_tree()\n",
    "tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "gLcsoJy5BIcW"
   },
   "outputs": [],
   "source": [
    "# @markdown **2.1 参数设置/Parameter setting (approx. 0 min)**\n",
    "# @markdown </br></br><font size=\"3\">**2.1.1 选择上传的文件类型(视频-video/音频-audio）/ Select the type of the file uploaded.**</font><br/>\n",
    "file_type = \"audio\"  # @param [\"audio\",\"video\"]\n",
    "\n",
    "# @markdown <font size=\"3\">**2.1.2 选择模型和语言 / Model size and language.**</font><br/>\n",
    "model_size = \"large-v2\"  # @param [\"base\",\"small\",\"medium\", \"large-v1\",\"large-v2\"]\n",
    "language = \"ja\"  # @param [\"ja\",\"zh\",\"en\",\"fr\", \"de\",\"es\",\"it\",\"pt\",\"ru\"]\n",
    "\n",
    "# @markdown <font size=\"3\">**2.1.3 分割行 / Split line**</font>\n",
    "# @markdown <br/><font size=\"2\">Option for split line text by spaces. The splited lines all use the same time stamp, with 'adjust_required' label as remark for manual adjustment.\n",
    "# @markdown <br/>将存在空格的单行文本分割为多行（多句）。分割后的若干行均临时采用相同时间戳，且添加了adjust_required标记提示调整时间戳避免叠轴\n",
    "# @markdown <br/>普通分割（Modest): 当空格后的文本长度超过5个字符，则另起一行\n",
    "# @markdown <br/>全部分割（Aggressive): 只要遇到空格即另起一行\n",
    "is_split = \"No\"  # @param [\"No\",\"Yes\"]\n",
    "split_method = \"Modest\"  # @param [\"Modest\",\"Aggressive\"]\n",
    "\n",
    "# @markdown <font size=\"3\">**2.1.4 高级设置 / Andvanced settings**（尚不可用/Under development</font>\n",
    "\n",
    "compression_ratio_threshold = 2.4 # @param {type:\"number\"}\n",
    "no_speech_threshold = 0.6 # @param {type:\"number\"}\n",
    "logprob_threshold = -1.0 # @param {type:\"number\"}\n",
    "condition_on_previous_text = \"True\" # @param [\"True\", \"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "z0igG7ruI-7q"
   },
   "outputs": [],
   "source": [
    "#@markdown **2.2 运行WhisperX/Run WhisperX (approx. ? min)**\n",
    "#@markdown </br><font size=\"2\">完成后srt文件将自动下载到谷歌云盘中\n",
    "#@markdown </br>SRT file will be downloaded automatically after finishing.</font><br/>\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import whisperx\n",
    "import whisper\n",
    "import time\n",
    "import pandas as pd\n",
    "from urllib.parse import quote_plus\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# assert file_name != \"\"\n",
    "# assert language != \"\"\n",
    "\n",
    "output_dir = os.path.dirname(drive_dir)\n",
    "try:\n",
    "    file_name = drive_dir\n",
    "    file_basename = file_name.split('.')[0]\n",
    "    output_dir = os.path.dirname(drive_dir)\n",
    "except Exception as e:\n",
    "    print(f'error: {e}')\n",
    "\n",
    "\n",
    "if file_type == \"video\":\n",
    "  print('提取音频中 Extracting audio from video file...')\n",
    "  os.system(f'ffmpeg -i {file_name} -ar 16000 -ac 1 -c:a pcm_s16le {file_basename}.wav')\n",
    "  print('提取完毕 Done.') \n",
    "\n",
    "audio_file = f'{file_name}'\n",
    "device = \"cuda\"\n",
    "torch.cuda.empty_cache()\n",
    "print('加载模型 Loading model...')\n",
    "model = whisper.load_model(model_size, device)\n",
    "\n",
    "# Original whisper transcribe\n",
    "tic = time.time()\n",
    "print('识别中 Transcribe in progress...')\n",
    "result = model.transcribe(audio_file, language= language)\n",
    "\n",
    "# Load alignment model and metadata\n",
    "print('加载调整模型 Load alignment model...')\n",
    "# model_id = \"jonatasgrosman/wav2vec2-large-xlsr-53-japanese\"\n",
    "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "\n",
    "# Align whisper output\n",
    "print('调整识别结果 Align whisper output...')\n",
    "result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n",
    "\n",
    "toc = time.time()\n",
    "print('识别完毕 Done')\n",
    "print(f'Time consumpution {toc-tic} s')\n",
    "\n",
    "#Write SRT file\n",
    "from whisperx.utils import write_srt\n",
    "with open(Path(output_dir) / (file_basename + \".srt\"), \"w\", encoding=\"utf-8\") as srt:\n",
    "    write_srt(result[\"segments\"], file=srt)\n",
    "\n",
    "'''#Convert SRT to ASS\n",
    "from srt2ass import srt2ass\n",
    "assSub = srt2ass(file_basename + \".srt\", sub_style, is_split,split_method)\n",
    "print('ASS subtitle saved as: ' + assSub)\n",
    "files.download(assSub)\n",
    "# os.remove(file_basename + \".srt\")'''\n",
    "\n",
    "print('字幕生成完毕 Subtitle generated!')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "k5n2xrB631JV"
   },
   "outputs": [],
   "source": [
    "#@title **【实验功能】Experimental Features**\n",
    "\n",
    "# @markdown **3.1 AI文本翻译/AI Translation (approx. ? min)**\n",
    "# @markdown </br><font size=\"2\">此功能允许用户使用AI翻译服务对识别的字幕文件做逐行翻译，并以相同的格式生成双语对照字幕。\n",
    "# @markdown </br>This feature allow users to translate previously transcribed subtitle text line by line using AI translation.\n",
    "# @markdown </br>Then generate bilingual subtitle files in same sub style.Read documentaion to learn more.</font>\n",
    "\n",
    "# @markdown <font size=\"2\">我无意在这里扩展太多字幕翻译的相关功能，因为这并不需要用到Google Colab提供的显存资源，在这里运行是一种浪费，反而还容易因为运行时间限制而崩溃。目前已经有很多调用API实现AI翻译的方案，并且这些工具还在迅速发展中。我后续会试验和整理一些放在我的主页上。\n",
    "# @markdown </br>希望在本地使用字幕翻译功能的用户，推荐尝试 [subtitle-translator-electron](https://github.com/gnehs/subtitle-translator-electron)</font>\n",
    "\n",
    "# @markdown **ChatGPT:**\n",
    "# @markdown </br><font size=\"2\">要使用ChatGPT翻译，请填入你自己的OpenAI API Key，目标语言，输出类型，然后执行单元格。\n",
    "# @markdown </br>Please input your own OpenAI API Key, then execute this cell.</font>\n",
    "openai_key = '' # @param {type:\"string\"}\n",
    "target_language = 'zh-hans'# @param [\"zh-hans\",\"english\"]\n",
    "output_format = \"ass\"  # @param [\"ass\",\"srt\"]\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import codecs\n",
    "import regex as re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from google.colab import files\n",
    "from IPython.display import clear_output \n",
    "\n",
    "!pip install openai\n",
    "!pip install pysubs2\n",
    "import openai\n",
    "import pysubs2\n",
    "\n",
    "clear_output()\n",
    "\n",
    "sub_source = \"use_transcribed\" \n",
    "if sub_source == 'upload_new':\n",
    "  uploaded = files.upload()\n",
    "  sub_name = list(uploaded.keys())[0]\n",
    "  sub_basename = Path(sub_name).stem\n",
    "elif sub_source == 'use_transcribed':\n",
    "  sub_name = file_basenames[0] +'.ass'\n",
    "  sub_basename = file_basenames[0]\n",
    "\n",
    "# original code\n",
    "class ChatGPTAPI():\n",
    "    def __init__(self, key, language):\n",
    "        self.key = key\n",
    "        # self.keys = itertools.cycle(key.split(\",\"))\n",
    "        self.language = language\n",
    "        self.key_len = len(key.split(\",\"))\n",
    "\n",
    "\n",
    "    # def rotate_key(self):\n",
    "    #     openai.api_key = next(self.keys)\n",
    "\n",
    "    def translate(self, text):\n",
    "        # print(text)\n",
    "        # self.rotate_key()\n",
    "        openai.api_key = self.key\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        # english prompt here to save tokens\n",
    "                        \"content\": f\"Please help me to translate,`{text}` to {self.language}, please return only translated content not include the origin text\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            t_text = (\n",
    "                completion[\"choices\"][0]\n",
    "                .get(\"message\")\n",
    "                .get(\"content\")\n",
    "                .encode(\"utf8\")\n",
    "                .decode()\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # TIME LIMIT for open api , pay to reduce the waiting time\n",
    "            sleep_time = int(60 / self.key_len)\n",
    "            time.sleep(sleep_time)\n",
    "            print(e, f\"will sleep  {sleep_time} seconds\")\n",
    "            # self.rotate_key()\n",
    "            openai.api_key = self.key\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Please help me to translate,`{text}` to {self.language}, please return only translated content not include the origin text\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            t_text = (\n",
    "                completion[\"choices\"][0]\n",
    "                .get(\"message\")\n",
    "                .get(\"content\")\n",
    "                .encode(\"utf8\")\n",
    "                .decode()\n",
    "            )\n",
    "        # print(t_text)\n",
    "        return t_text\n",
    "\n",
    "class SubtitleTranslator():\n",
    "\n",
    "    def __init__(self, sub_src, model, key, language):\n",
    "        self.sub_src = sub_src\n",
    "        self.translate_model = model(key, language)\n",
    "\n",
    "    def translate_by_line(self):\n",
    "        sub_trans = pysubs2.load(self.sub_src)\n",
    "        total_lines = len(sub_trans)\n",
    "        for line in tqdm(sub_trans,total = total_lines):\n",
    "            line_trans = self.translate_model.translate(line.text)\n",
    "            line.text += (r'\\N'+ line_trans)\n",
    "            print(line_trans)\n",
    "\n",
    "        return sub_trans\n",
    "\n",
    "\n",
    "clear_output()\n",
    "\n",
    "translate_model = ChatGPTAPI\n",
    "\n",
    "assert translate_model is not None, \"unsupported model\"\n",
    "OPENAI_API_KEY = openai_key\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise Exception(\n",
    "        \"OpenAI API key is not provided.\"\n",
    "    )\n",
    "\n",
    "t = SubtitleTranslator(\n",
    "    sub_src=sub_name,\n",
    "    model= translate_model,\n",
    "    key = OPENAI_API_KEY,\n",
    "    language=target_language)\n",
    "\n",
    "translation = t.translate_by_line()\n",
    "\n",
    "#Download ass file\n",
    "\n",
    "if output_format == 'ass':\n",
    "  translation.save(sub_basename + '_translation.ass')\n",
    "  files.download(sub_basename + '_translation.ass')\n",
    "elif output_format == 'srt':\n",
    "  translation.save(sub_basename + '_translation.srt')\n",
    "  files.download(sub_basename + '_translation.srt')\n",
    "\n",
    "print('双语字幕生成完毕 Translated subtitles generated!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
