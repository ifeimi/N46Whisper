{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cEAvBF4zgXX4"
      },
      "source": [
        "# Whisper48\n",
        "\n",
        "<font size='4'>**对于中文用户，推荐在使用前阅读[常见问题说明](https://github.com/Ayanaminn/N46Whisper/blob/main/FAQ.md)。如果你觉得本应用对你有所帮助，欢迎帮助扩散给更多的人。**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ2x8S7RMF9i"
      },
      "source": [
        "## 更新/What's New：\n",
        "2023.3.15:\n",
        "* 添加按空格分割同一行中的多词/句功能/ Allow users to split multiple words/sententces in one line.\n",
        "* 修订文档以及其它一些优化。/ Update doc and other minor fixes.\n",
        "\n",
        "2023.3.12:\n",
        "* 添加chatGPT翻译并生成双语字幕功能/ Add chatGPT translation and bilingual subtitle file generation features.\n",
        "* 修订文档以及其它一些优化。/ Update doc and other minor fixes.\n",
        "\n",
        "2023.1.26:\n",
        "* 修正代码以反映Whisper的更新/ Update\n",
        " script to reflect recent updates from Whisper.\n",
        "\n",
        "2022.12.31：\n",
        "* 添加了允许用户从挂载的谷歌云盘中直接选择要转换的文件的功能。本地上传文件的选项仍然保留。/ Allow user to select files directly from mounted google drive.\n",
        "* 修订文档以及其它一些优化。/ Update doc and other minor fixes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laXaXrgPvCOn"
      },
      "source": [
        "## **<font size='5'>顺次点击下方每个单元格左侧的“运行”图标，以开始使用**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nw72_bK3AS1d"
      },
      "outputs": [],
      "source": [
        "#@markdown **挂载你的谷歌网盘/Mount Google Drive** \n",
        "#@markdown **</br>【重要】:** 务必在\"修改\"->\"笔记本设置\"->\"硬件加速器\"中选择GPU！否则处理速度会非常慢。\n",
        "#@markdown **</br>【IMPORTANT】:** Make sure you select GPU as hardware accelerator in notebook settings, otherwise the processing speed will be very slow.\n",
        "!pip install geemap\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import os\n",
        "import logging\n",
        "from IPython.display import clear_output \n",
        "import geemap\n",
        "\n",
        "clear_output()\n",
        "drive.mount('/drive')\n",
        "print('Google Drive mounted，please execute next cell')\n",
        "print('谷歌云盘挂载完毕，请执行下个单元格')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fjm3tYISAk9P"
      },
      "outputs": [],
      "source": [
        "#@markdown **配置Whisper/Setup Whisper**\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! wget https://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@raw.githubusercontent.com/Ayanaminn/N46Whisper/main/srt2ass.py\n",
        "clear_output()\n",
        "print('Whisper installed，please execute next cell')\n",
        "print('语音识别库配置完毕，请执行下个单元格')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "30dM9s2J27A5"
      },
      "outputs": [],
      "source": [
        "#@markdown **从谷歌网盘选择文件/Select File From Google Drive**\n",
        "\n",
        "# @markdown <font size=\"2\">Navigate to the file you want to transcribe, left-click to highlight the file, then click 'Select' button to confirm.\n",
        "# @markdown <br/>从网盘目录中选择要转换的文件(视频/音频），单击选中文件，点击'Select'按钮以确认。</font><br/>\n",
        "# @markdown <br/><font size=\"2\">If use local file, ignore this cell and move to the next.\n",
        "# @markdown <br/>若希望从本地上传文件，则跳过此步执行下一单元格。</font><br/>\n",
        "# @markdown <br/><font size=\"2\">If file uploaded to drive after execution, execute this cell again to refresh.\n",
        "# @markdown <br/>若到这一步才上传文件到谷歌盘，则重复执行本单元格以刷新文件列表。</font>\n",
        "from ipytree import Tree, Node\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interactive\n",
        "import os\n",
        "from google.colab import output \n",
        "output.enable_custom_widget_manager()\n",
        "use_drive = True\n",
        "global drive_dir\n",
        "drive_dir = ''\n",
        "\n",
        "def file_tree():\n",
        "    # create widgets as a simple file browser\n",
        "    full_widget = widgets.HBox()\n",
        "    left_widget = widgets.VBox()\n",
        "    right_widget = widgets.VBox()\n",
        "\n",
        "    path_widget = widgets.Text()\n",
        "    path_widget.layout.min_width = '300px'\n",
        "    select_widget = widgets.Button(\n",
        "      description='Select', button_style='primary', tooltip='Select current media file.'\n",
        "      )\n",
        "    drive_url = widgets.Output()\n",
        "\n",
        "    right_widget.children = [select_widget]\n",
        "    full_widget.children = [left_widget]\n",
        "\n",
        "    tree_widget = widgets.Output()\n",
        "    tree_widget.layout.max_width = '300px'\n",
        "    tree_widget.overflow = 'auto'\n",
        "\n",
        "    left_widget.children = [path_widget,tree_widget]\n",
        "\n",
        "    # init file tree\n",
        "    my_tree = Tree(multiple_selection=False)\n",
        "    my_tree_dict = {}\n",
        "    media_names = []\n",
        "\n",
        "    def select_file(b):\n",
        "        global drive_dir \n",
        "        drive_dir = path_widget.value\n",
        "        # full_widget.disabled = True\n",
        "        clear_output()\n",
        "        print('File selected，please execute next cell')\n",
        "        print('已选择文件，请执行下个单元格')\n",
        "    #     if (out_file not in my_tree_dict.keys()) and (out_dir in my_tree_dict.keys()):\n",
        "    #         node = Node(os.path.basename(out_file))\n",
        "    #         my_tree_dict[out_file] = node\n",
        "    #         parent_node = my_tree_dict[out_dir]\n",
        "    #         parent_node.add_node(node)\n",
        "\n",
        "    select_widget.on_click(select_file)\n",
        "\n",
        "    def handle_file_click(event):\n",
        "        if event['new']:\n",
        "            cur_node = event['owner']\n",
        "            for key in my_tree_dict.keys():\n",
        "                if (cur_node is my_tree_dict[key]) and (os.path.isfile(key)):\n",
        "                    try:\n",
        "                        with open(key) as f:\n",
        "                            path_widget.value = key\n",
        "                            path_widget.disabled = False\n",
        "                            select_widget.disabled = False\n",
        "                            full_widget.children = [left_widget, right_widget]\n",
        "                    except Exception as e:\n",
        "                        path_widget.value = key\n",
        "                        path_widget.disabled = True\n",
        "                        select_widget.disabled = True\n",
        "\n",
        "                        return\n",
        "\n",
        "    def handle_folder_click(event):\n",
        "        if event['new']:\n",
        "            full_widget.children = [left_widget]\n",
        "\n",
        "    # redirect cwd to default drive root path and add nodes\n",
        "    my_dir = '/drive/MyDrive'\n",
        "    my_root_name = my_dir.split('/')[-1]\n",
        "    my_root_node = Node(my_root_name)\n",
        "    my_tree_dict[my_dir] = my_root_node\n",
        "    my_tree.add_node(my_root_node)\n",
        "    my_root_node.observe(handle_folder_click, 'selected')\n",
        "\n",
        "    for root, d_names, f_names in os.walk(my_dir):\n",
        "        folders = root.split('/')\n",
        "        for folder in folders:\n",
        "            if folder.startswith('.'):\n",
        "                continue\n",
        "        for d_name in d_names:\n",
        "            if d_name.startswith('.'):\n",
        "                d_names.remove(d_name)\n",
        "        for f_name in f_names:\n",
        "            # if f_name.startswith('.'):\n",
        "            #     f_names.remove(f_name)\n",
        "            # only add media files\n",
        "            if f_name.endswith(('mp3','m4a','flac','aac','wav','mp4','mkv','ts','flv')):\n",
        "                media_names.append(f_name)\n",
        "\n",
        "        d_names.sort()\n",
        "        f_names.sort()\n",
        "        media_names.sort()\n",
        "        keys = my_tree_dict.keys()\n",
        "\n",
        "        if root not in my_tree_dict.keys():\n",
        "          # print(f'root name is {root}') # folder path\n",
        "          name = root.split('/')[-1] # folder name\n",
        "          # print(f'folder name is {name}')\n",
        "          dir_name = os.path.dirname(root) # parent path of folder\n",
        "          # print(f'dir name is {dir_name}')\n",
        "          parent_node = my_tree_dict[dir_name]\n",
        "          node = Node(name)\n",
        "          my_tree_dict[root] = node\n",
        "          parent_node.add_node(node)\n",
        "          node.observe(handle_folder_click, 'selected')\n",
        "\n",
        "        if len(media_names) > 0:\n",
        "              parent_node = my_tree_dict[root] # parent folders\n",
        "              # print(parent_node)\n",
        "              parent_node.opened = False\n",
        "              for f_name in media_names:\n",
        "                  node = Node(f_name)\n",
        "                  node.icon = 'file' \n",
        "                  full_path = os.path.join(root, f_name)\n",
        "                  # print(full_path)\n",
        "                  my_tree_dict[full_path] = node\n",
        "                  parent_node.add_node(node)\n",
        "                  node.observe(handle_file_click, 'selected')\n",
        "        media_names.clear()\n",
        "\n",
        "    with tree_widget:\n",
        "      tree_widget.clear_output()\n",
        "      display(my_tree)\n",
        "\n",
        "    return full_widget\n",
        "\n",
        "\n",
        "tree= file_tree()\n",
        "tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VF_eOkuYbrBj"
      },
      "outputs": [],
      "source": [
        "#@markdown **从本地上传文件/Upload Local File**\n",
        "# @markdown <br/><font size=\"2\">If use file in google drive, ignore this cell and move to the next.\n",
        "# @markdown <br/>若已选择谷歌盘中的文件，则跳过此步执行下一单元格。</font>\n",
        "\n",
        "from google.colab import files\n",
        "use_drive = False\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gLcsoJy5BIcW"
      },
      "outputs": [],
      "source": [
        "# @markdown **参数设置/Required settings:**\n",
        "\n",
        "\n",
        "# @markdown **</br>【IMPORTANT】:**<font size=\"2\">Select uploaded file type.\n",
        "# @markdown **</br>【重要】:** 选择上传的文件类型(视频-video/音频-audio）。</font>\n",
        "\n",
        "# encoding:utf-8\n",
        "file_type = \"audio\"  # @param [\"audio\",\"video\"]\n",
        "\n",
        "# @markdown <font size=\"2\">Model size will affect the processing time and transcribe quality.\n",
        "# @markdown <br/>The default source language is Japanese.Please input your own source language if applicable.\n",
        "# @markdown <br/>模型大小将影响转录时间和质量, 默认使用最新发布的large-v2模型以节省试错时间\n",
        "# @markdown <br/>默认识别语言为日语，若使用其它语言的视频请自行输入即可。\n",
        "# @markdown <br/>请注意：large-v2在某些情况下可能未必优于large-v1，请用户自行选择\n",
        "model_size = \"large-v2\"  # @param [\"base\",\"small\",\"medium\", \"large-v1\",\"large-v2\"]\n",
        "language = \"japanese\"  # @param {type:\"string\"}\n",
        "# @markdown <font size=\"2\">Option for split line text by spaces. The splited lines all use the same time stamp, with 'adjust_required' label as remark for manual adjustment.\n",
        "# @markdown <br/>将存在空格的单行文本分割为多行（多句）。分割后的若干行均临时采用相同时间戳，且添加了adjust_required标记提示调整时间戳避免叠轴\n",
        "# @markdown <br/>普通分割（Modest): 当空格后的文本长度超过5个字符，则另起一行\n",
        "# @markdown <br/>全部分割（Aggressive): 只要遇到空格即另起一行\n",
        "is_split = \"No\"  # @param [\"No\",\"Yes\"]\n",
        "split_method = \"Modest\"  # @param [\"Modest\",\"Aggressive\"]\n",
        "# @markdown <font size=\"2\">Please contact us if you want to have your sub style integrated.\n",
        "# @markdown <br/>当前支持生成字幕格式：\n",
        "# @markdown <br/><li>ikedaCN - 特蕾纱熊猫观察会字幕组\n",
        "# @markdown <br/><li>sugawaraCN - 坂上之月字幕组\n",
        "# @markdown <br/><li>kaedeCN - 三番目の枫字幕组\n",
        "# @markdown <br/><li>taniguchiCN - 泪痣愛季応援団\n",
        "# @markdown <br/><li>asukaCN - 暗鳥其实很甜字幕组\n",
        "sub_style = \"default\"  # @param [\"default\", \"ikedaCN\", \"kaedeCN\",\"sugawaraCN\",\"taniguchiCN\",\"asukaCN\"]\n",
        "\n",
        "# @markdown **高级设置/Andvanced settings:（尚不可用/Under development）**\n",
        "\n",
        "# @markdown <font size=\"2\">Don't change anything here unless you know what you are doing.\n",
        "# @markdown <br/>调节以下参数可能会提高转录质量并避免一些问题，但是不懂请不要调\n",
        "\n",
        "compression_ratio_threshold = 2.4 # @param {type:\"number\"}\n",
        "no_speech_threshold = 0.6 # @param {type:\"number\"}\n",
        "logprob_threshold = -1.0 # @param {type:\"number\"}\n",
        "condition_on_previous_text = \"True\" # @param [\"True\", \"False\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z0igG7ruI-7q"
      },
      "outputs": [],
      "source": [
        "#@markdown **运行Whisper/Run Whisper**\n",
        "#@markdown </br>完成后ass文件将自动下载到本地/ass file will be auto downloaded after finish.\n",
        "\n",
        "import os\n",
        "import ffmpeg\n",
        "import subprocess\n",
        "import torch\n",
        "import whisper\n",
        "import time\n",
        "import pandas as pd\n",
        "from urllib.parse import quote_plus\n",
        "from pathlib import Path\n",
        "import sys\n",
        "# assert file_name != \"\"\n",
        "# assert language != \"\"\n",
        "\n",
        "if use_drive:\n",
        "    output_dir = os.path.dirname(drive_dir)\n",
        "    try:\n",
        "        file_name = drive_dir\n",
        "        # print(file_name)\n",
        "        file_basename = file_name.split('.')[0]\n",
        "        # print(file_basename)\n",
        "        output_dir = os.path.dirname(drive_dir)\n",
        "    except Exception as e:\n",
        "            print(f'error: {e}')\n",
        "else:\n",
        "    sys.path.append('/drive/content')\n",
        "    if not os.path.exists(file_name):\n",
        "      raise ValueError(f\"No {file_name} found in current path.\")\n",
        "    else:\n",
        "        try:\n",
        "            file_basename = Path(file_name).stem\n",
        "            output_dir = Path(file_name).parent.resolve()\n",
        "            # print(file_basename)\n",
        "            # print(output_dir)      \n",
        "        except Exception as e:\n",
        "            print(f'error: {e}')\n",
        "\n",
        "if file_type == \"video\":\n",
        "  print('提取音频中 Extracting audio from video file...')\n",
        "  os.system(f'ffmpeg -i {file_name} -f mp3 -ab 192000 -vn {file_basename}.mp3')\n",
        "  print('提取完毕 Done.') \n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print('加载模型 Loading model...')\n",
        "model = whisper.load_model(model_size)\n",
        "\n",
        "#Transcribe\n",
        "tic = time.time()\n",
        "print('识别中 Transcribe in progress...')\n",
        "result = model.transcribe(audio = f'{file_name}', language= language, verbose=False)\n",
        "toc = time.time()\n",
        "print('识别完毕 Done')\n",
        "print(f'Time consumpution {toc-tic}s')\n",
        "\n",
        "#Write SRT file\n",
        "from whisper.utils import WriteSRT\n",
        "with open(Path(output_dir) / (file_basename + \".srt\"), \"w\", encoding=\"utf-8\") as srt:\n",
        "    writer = WriteSRT(output_dir)\n",
        "    writer.write_result(result, srt)\n",
        "#Convert SRT to ASS\n",
        "\n",
        "from srt2ass import srt2ass\n",
        "assSub = srt2ass(file_basename + \".srt\", sub_style, is_split,split_method)\n",
        "print('ASS subtitle saved as: ' + assSub)\n",
        "files.download(assSub)\n",
        "# os.remove(file_basename + \".srt\")\n",
        "torch.cuda.empty_cache()\n",
        "print('字幕生成完毕 All done!')\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k5n2xrB631JV"
      },
      "outputs": [],
      "source": [
        "# @markdown **【实验功能】Experimental Features:**\n",
        "\n",
        "# @markdown **AI文本翻译/AI Translation:**\n",
        "# @markdown **</br>**<font size=\"2\"> 此功能允许用户使用AI翻译服务对识别的字幕文件做逐行翻译，并以相同的格式生成双语对照字幕。\n",
        "# @markdown **</br>**阅读项目文档以了解更多。</font>\n",
        "# @markdown **</br>**<font size=\"2\"> This feature allow users to translate previously transcribed subtitle text line by line using AI translation.\n",
        "# @markdown **</br>**Then generate bilingual subtitle files in same sub style.Read documentaion to learn more.</font>\n",
        "\n",
        "# @markdown **chatGPT:**\n",
        "# @markdown **</br>**<font size=\"2\"> 要使用chatGPT翻译，请填入你自己的OpenAI API Key，然后执行单元格。</font>\n",
        "# @markdown **</br>**<font size=\"2\"> Please input your own OpenAI API Key, then execute this cell.</font>\n",
        "# @markdown **</br>**<font size=\"2\">【注意】 免费的API对速度有所限制，需要较长时间，用户可以自行考虑付费方案。</font>\n",
        "# @markdown **</br>**<font size=\"2\">【Note】There are limitaions on usage for free API, consider paid plan to speed up.</font>\n",
        "\n",
        "!pip install openai\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import codecs\n",
        "import regex as re\n",
        "import openai\n",
        "from srt2ass import STYLE_DICT\n",
        "\n",
        "# test for code obfuscation\n",
        "class ChatGPTAPI ():#line:12\n",
        "    def __init__ (OO000OOOO0OOOOOOO ,OO00O0000O0O0O0O0 ,O00O00OO0OO0OO0OO ):#line:13\n",
        "        OO000OOOO0OOOOOOO .key =OO00O0000O0O0O0O0 #line:14\n",
        "        OO000OOOO0OOOOOOO .language =O00O00OO0OO0OO0OO #line:16\n",
        "        OO000OOOO0OOOOOOO .key_len =len (OO00O0000O0O0O0O0 .split (\",\"))#line:17\n",
        "    def translate (OOO0OO000O0OOO0OO ,OO00O0OOOO00O0O00 ):#line:23\n",
        "        # print (OO00O0OOOO00O0O00 )#line:24\n",
        "        openai .api_key =OOO0OO000O0OOO0OO .key #line:26\n",
        "        try :#line:27\n",
        "            OO00OO000O0O000O0 =openai .ChatCompletion .create (model =\"gpt-3.5-turbo\",messages =[{\"role\":\"user\",\"content\":f\"Please help me to translate,`{OO00O0OOOO00O0O00}` to {OOO0OO000O0OOO0OO.language}, please return only translated content not include the origin text\",}],)#line:37\n",
        "            O00O000000000O00O =(OO00OO000O0O000O0 [\"choices\"][0 ].get (\"message\").get (\"content\").encode (\"utf8\").decode ())#line:44\n",
        "        except Exception as OO0O000000OO00000 :#line:45\n",
        "            O00O00O00OOOO00O0 =int (60 /OOO0OO000O0OOO0OO .key_len )#line:47\n",
        "            time .sleep (O00O00O00OOOO00O0 )#line:48\n",
        "            print (OO0O000000OO00000 ,f\"will sleep  {O00O00O00OOOO00O0} seconds\")#line:49\n",
        "            openai .api_key =OOO0OO000O0OOO0OO .key #line:51\n",
        "            OO00OO000O0O000O0 =openai .ChatCompletion .create (model =\"gpt-3.5-turbo\",messages =[{\"role\":\"user\",\"content\":f\"Please help me to translate,`{OO00O0OOOO00O0O00}` to {OOO0OO000O0OOO0OO.language}, please return only translated content not include the origin text\",}],)#line:60\n",
        "            O00O000000000O00O =(OO00OO000O0O000O0 [\"choices\"][0 ].get (\"message\").get (\"content\").encode (\"utf8\").decode ())#line:67\n",
        "        return O00O000000000O00O #line:69\n",
        "\n",
        "# original code\n",
        "# class ChatGPTAPI():\n",
        "#     def __init__(self, key, language):\n",
        "#         self.key = key\n",
        "#         # self.keys = itertools.cycle(key.split(\",\"))\n",
        "#         self.language = language\n",
        "#         self.key_len = len(key.split(\",\"))\n",
        "\n",
        "\n",
        "#     # def rotate_key(self):\n",
        "#     #     openai.api_key = next(self.keys)\n",
        "\n",
        "#     def translate(self, text):\n",
        "#         print(text)\n",
        "#         # self.rotate_key()\n",
        "#         openai.api_key = self.key\n",
        "#         try:\n",
        "#             completion = openai.ChatCompletion.create(\n",
        "#                 model=\"gpt-3.5-turbo\",\n",
        "#                 messages=[\n",
        "#                     {\n",
        "#                         \"role\": \"user\",\n",
        "#                         # english prompt here to save tokens\n",
        "#                         \"content\": f\"Please help me to translate,`{text}` to {self.language}, please return only translated content not include the origin text\",\n",
        "#                     }\n",
        "#                 ],\n",
        "#             )\n",
        "#             t_text = (\n",
        "#                 completion[\"choices\"][0]\n",
        "#                 .get(\"message\")\n",
        "#                 .get(\"content\")\n",
        "#                 .encode(\"utf8\")\n",
        "#                 .decode()\n",
        "#             )\n",
        "#         except Exception as e:\n",
        "#             # TIME LIMIT for open api , pay to reduce the waiting time\n",
        "#             sleep_time = int(60 / self.key_len)\n",
        "#             time.sleep(sleep_time)\n",
        "#             print(e, f\"will sleep  {sleep_time} seconds\")\n",
        "#             # self.rotate_key()\n",
        "#             openai.api_key = self.key\n",
        "#             completion = openai.ChatCompletion.create(\n",
        "#                 model=\"gpt-3.5-turbo\",\n",
        "#                 messages=[\n",
        "#                     {\n",
        "#                         \"role\": \"user\",\n",
        "#                         \"content\": f\"Please help me to translate,`{text}` to {self.language}, please return only translated content not include the origin text\",\n",
        "#                     }\n",
        "#                 ],\n",
        "#             )\n",
        "#             t_text = (\n",
        "#                 completion[\"choices\"][0]\n",
        "#                 .get(\"message\")\n",
        "#                 .get(\"content\")\n",
        "#                 .encode(\"utf8\")\n",
        "#                 .decode()\n",
        "#             )\n",
        "#         # print(t_text)\n",
        "#         return t_text\n",
        "\n",
        "class SubtitleTranslator():\n",
        "    def __init__(self, srt_src, model, key, language, sub_style):\n",
        "        self.srt_src = srt_src\n",
        "        self.translate_model = model(key, language)\n",
        "        self.sub_style = sub_style\n",
        "\n",
        "\n",
        "    def read_srt(self, srt_src):\n",
        "        # use correct codec to encode the input file\n",
        "        encodings = [\"utf-32\", \"utf-16\", \"utf-8\", \"cp1252\", \"gb2312\", \"gbk\", \"big5\"]\n",
        "        tmp = ''\n",
        "        for enc in encodings:\n",
        "            try:\n",
        "                with codecs.open(srt_src, mode=\"r\", encoding=enc) as fd:\n",
        "                    # return an instance of StreamReaderWriter\n",
        "                    tmp = fd.read()\n",
        "                    break\n",
        "            except:\n",
        "                # print enc + ' failed'\n",
        "                continue\n",
        "        return [tmp, enc]\n",
        "\n",
        "    def extract_srt(self):\n",
        "        src = self.read_srt(self.srt_src)\n",
        "        content = src[0]\n",
        "        # encoding = src[1] # Will not encode so do not need to pass codec para\n",
        "        src = ''\n",
        "        utf8bom = ''\n",
        "\n",
        "        if u'\\ufeff' in content:\n",
        "            content = content.replace(u'\\ufeff', '')\n",
        "            utf8bom = u'\\ufeff'\n",
        "\n",
        "        content = content.replace(\"\\r\", \"\")\n",
        "        sub_lines = [x.strip() for x in content.split(\"\\n\") if x.strip()]\n",
        "        return sub_lines\n",
        "\n",
        "    def translate_by_line(self):\n",
        "        utf8bom = ''\n",
        "        subLines = ''\n",
        "        dlgLines = ''\n",
        "        lineCount = 0\n",
        "        sub_lines = self.extract_srt()\n",
        "        output_file = '.'.join(self.srt_src.split('.')[:-1])\n",
        "        output_file += '_translate.ass'\n",
        "\n",
        "        for ln in range(len(sub_lines)):\n",
        "            line = sub_lines[ln]\n",
        "            # if line index element\n",
        "            if line.isdigit() and re.match('-?\\d\\d:\\d\\d:\\d\\d', sub_lines[(ln + 1)]):\n",
        "                # for each index, create an empty dialogue line for construct ass line\n",
        "                if dlgLines:\n",
        "                    subLines += dlgLines + \"\\n\"\n",
        "                dlgLines = ''\n",
        "                lineCount = 0\n",
        "                continue\n",
        "            else:\n",
        "                # if time stamp element, construct the time stamp part for the dialogue line\n",
        "                if re.match('-?\\d\\d:\\d\\d:\\d\\d', line):\n",
        "                    line = line.replace('-0', '0')\n",
        "                    if self.sub_style == 'default':\n",
        "                        dlgLines += 'Dialogue: 0,' + line + ',default,,0,0,0,,'\n",
        "                    elif self.sub_style == 'ikedaCN':\n",
        "                        dlgLines += 'Dialogue: 0,' + line + ',池田字幕1080p,,0,0,0,,'\n",
        "                    elif self.sub_style == 'sugawaraCN':\n",
        "                        dlgLines += 'Dialogue: 0,' + line + ',中字 1080P,,0,0,0,,'\n",
        "                    elif self.sub_style == 'kaedeCN':\n",
        "                        dlgLines += 'Dialogue: 0,' + line + ',den SR红色,,0,0,0,,'\n",
        "                    elif self.sub_style == 'taniguchiCN':\n",
        "                        dlgLines += 'Dialogue: 0,' + line + ',正文_1080P,,0,0,0,,'\n",
        "                # if text element, construct(append) the text part for the dialogue line\n",
        "                else:\n",
        "                    if lineCount < 2:\n",
        "                        t_line = self.translate_model.translate(line)\n",
        "                        dlgLines += line + (r'\\N' + t_line.strip())\n",
        "\n",
        "                        print(line + (r'\\N' + t_line.strip()))\n",
        "                    else:\n",
        "                        t_line = self.translate_model.translate(line)\n",
        "                        dlgLines += \"\\n\" + line + (r'\\N' + t_line.strip())\n",
        "\n",
        "                        print(line + (r'\\N' + t_line.strip()))\n",
        "                lineCount += 1\n",
        "            ln += 1\n",
        "\n",
        "        subLines += dlgLines + \"\\n\"\n",
        "\n",
        "        subLines = re.sub(r'\\d(\\d:\\d{2}:\\d{2}),(\\d{2})\\d', '\\\\1.\\\\2', subLines)\n",
        "        subLines = re.sub(r'\\s+-->\\s+', ',', subLines)\n",
        "\n",
        "        if self.sub_style == 'default':\n",
        "            head_name = 'head_str_default'\n",
        "        elif self.sub_style == 'ikedaCN':\n",
        "            head_name = 'head_str_ikeda'\n",
        "        elif self.sub_style == 'sugawaraCN':\n",
        "            head_name = 'head_str_sugawara'\n",
        "        elif self.sub_style == 'kaedeCN':\n",
        "            head_name = 'head_str_kaede'\n",
        "        elif self.sub_style == \"taniguchiCN\":\n",
        "            head_name = 'head_str_taniguchi'\n",
        "\n",
        "        head_str = STYLE_DICT.get(head_name)\n",
        "        output_str = utf8bom + head_str + '\\n' + subLines\n",
        "        # encode again for head string\n",
        "        output_str = output_str.encode('utf8')\n",
        "\n",
        "        with open(output_file, 'wb') as output:\n",
        "            output.write(output_str)\n",
        "\n",
        "        output_file = output_file.replace('\\\\', '\\\\\\\\')\n",
        "        output_file = output_file.replace('/', '//')\n",
        "        return output_file\n",
        "\n",
        "\n",
        "\n",
        "clear_output()\n",
        "\n",
        "translate_model = ChatGPTAPI\n",
        "openai_key = '' # @param {type:\"string\"}\n",
        "target_language = 'zh-hans'\n",
        "srt_file = file_basename + \".srt\"\n",
        "\n",
        "assert translate_model is not None, \"unsupported model\"\n",
        "OPENAI_API_KEY = openai_key\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise Exception(\n",
        "        \"OpenAI API key not provided, please google how to obtain it\"\n",
        "    )\n",
        "# else:\n",
        "#     OPENAI_API_KEY = openai_key\n",
        "\n",
        "t = SubtitleTranslator(\n",
        "    srt_src=srt_file,\n",
        "    model= translate_model,\n",
        "    key = OPENAI_API_KEY,\n",
        "    language=target_language,\n",
        "    sub_style = sub_style)\n",
        "\n",
        "translation = t.translate_by_line()\n",
        "files.download(translation)\n",
        "print('双语字幕生成完毕 All done!')\n",
        "\n",
        "# @markdown **</br>**<font size='4'>**实验功能的开发亦是为了尝试帮助大家更有效率的制作字幕。但是只有在用户实际使用体验反馈的基础上，此应用才能不断完善，如果您有任何想法，都欢迎以任何方式联系我，提出[issue](https://github.com/Ayanaminn/N46Whisper/issues)或者分享在[讨论区](https://github.com/Ayanaminn/N46Whisper/discussions)。**\n",
        "# @markdown **</br>**<font size='4'>**The efficacy of this application cannot get improved without the feedbacks from everyday users.Please feel free to share your thoughts with me or post it [here](https://github.com/Ayanaminn/N46Whisper/discussions)**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
